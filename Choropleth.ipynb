{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from IPython.display import display\n",
    "import folium\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from sklearn.metrics import recall_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amz = pd.read_csv(\"Data/CSV//amazon_labelled_locations.csv\",thousands=\",\")\n",
    "moodys = pd.read_csv(\"Data/CSV/MoodysData-ACS.csv\",thousands=\",\")\n",
    "us_county = pd.read_csv(\"Data/national_county.txt\",names=[\"state\",\"state_code\",\"county_code\",\"county\",\"FIPS_class_code\"],dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_state_abbrev = {\"Alabama\": \"AL\",\"Alaska\": \"AK\",\"Arizona\": \"AZ\",\"Arkansas\": \"AR\",\"California\": \"CA\",\"Colorado\": \"CO\",\n",
    "                   \"Connecticut\": \"CT\",\"Delaware\": \"DE\",\"Florida\": \"FL\",\"Georgia\": \"GA\",\"Hawaii\": \"HI\",\"Idaho\": \"ID\",\n",
    "                   \"Illinois\": \"IL\",\"Indiana\": \"IN\",\"Iowa\": \"IA\",\"Kansas\": \"KS\",\"Kentucky\": \"KY\",\"Louisiana\": \"LA\",\n",
    "                   \"Maine\": \"ME\",\"Maryland\": \"MD\",\"Massachusetts\": \"MA\",\"Michigan\": \"MI\",\"Minnesota\": \"MN\",\n",
    "                   \"Mississippi\": \"MS\",\"Missouri\": \"MO\",\"Montana\": \"MT\",\"Nebraska\": \"NE\",\"Nevada\": \"NV\",\n",
    "                   \"New Hampshire\": \"NH\",\"New Jersey\": \"NJ\",\"New Mexico\": \"NM\",\"New York\": \"NY\",\"North Carolina\": \"NC\",\n",
    "                   \"North Dakota\": \"ND\",\"Ohio\": \"OH\",\"Oklahoma\": \"OK\",\"Oregon\": \"OR\",\"Pennsylvania\": \"PA\",\n",
    "                   \"Rhode Island\": \"RI\",\"South Carolina\": \"SC\",\"South Dakota\": \"SD\",\"Tennessee\": \"TN\",\"Texas\": \"TX\",\n",
    "                   \"Utah\": \"UT\",\"Vermont\": \"VT\",\"Virginia\": \"VA\",\"Washington\": \"WA\",\"West Virginia\": \"WV\",\n",
    "                   \"Wisconsin\": \"WI\",\"Wyoming\": \"WY\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Code</th>\n",
       "      <th>Location</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Year Opened</th>\n",
       "      <th>Description of Operation</th>\n",
       "      <th>Type</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>DPX1</td>\n",
       "      <td>500 S. 48th Street, Phoenix, Arizona, USA, 85034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May 2015</td>\n",
       "      <td>Delivery Station for Phoenix West Valley Co-lo...</td>\n",
       "      <td>Delivery Station</td>\n",
       "      <td>Maricopa County</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Code                                          Location  \\\n",
       "0  Arizona  DPX1  500 S. 48th Street, Phoenix, Arizona, USA, 85034   \n",
       "\n",
       "   Square Feet Year Opened                           Description of Operation  \\\n",
       "0          NaN    May 2015  Delivery Station for Phoenix West Valley Co-lo...   \n",
       "\n",
       "               Type           County     City    Year  \n",
       "0  Delivery Station  Maricopa County  Phoenix  2015.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Code</th>\n",
       "      <th>Include in Amazon Dataset</th>\n",
       "      <th>Years</th>\n",
       "      <th>Current Senior Most Rating*</th>\n",
       "      <th>Tax Backed Rating Description</th>\n",
       "      <th>State</th>\n",
       "      <th>Population (ACS Data)</th>\n",
       "      <th>Per Capita Income  (ACS Data)</th>\n",
       "      <th>Median Family Income  (ACS Data)</th>\n",
       "      <th>Median Home Value (ACS Data)</th>\n",
       "      <th>Median Gross Rent (ACS Data)</th>\n",
       "      <th>Occupied Housing Units (ACS Data)</th>\n",
       "      <th>Seasonal Homes (ACS Data)</th>\n",
       "      <th>No. Persons/Household (ACS Data)</th>\n",
       "      <th>Median Age (ACS Data)</th>\n",
       "      <th>% Below Poverty Level (ACS Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Median</td>\n",
       "      <td>Median</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Unnamed: 1  Code Include in Amazon Dataset   Years  \\\n",
       "0     Median     Median   NaN                       NaN  2017.0   \n",
       "\n",
       "  Current Senior Most Rating* Tax Backed Rating Description State  \\\n",
       "0                         NaN                           NaN   NaN   \n",
       "\n",
       "   Population (ACS Data)  Per Capita Income  (ACS Data)  \\\n",
       "0                    NaN                            NaN   \n",
       "\n",
       "   Median Family Income  (ACS Data)  Median Home Value (ACS Data)  \\\n",
       "0                               NaN                           NaN   \n",
       "\n",
       "   Median Gross Rent (ACS Data)  Occupied Housing Units (ACS Data)  \\\n",
       "0                           NaN                                NaN   \n",
       "\n",
       "   Seasonal Homes (ACS Data)  No. Persons/Household (ACS Data)  \\\n",
       "0                        NaN                               NaN   \n",
       "\n",
       "   Median Age (ACS Data)  % Below Poverty Level (ACS Data)  \n",
       "0                    NaN                               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>county</th>\n",
       "      <th>FIPS_class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state state_code county_code          county FIPS_class_code\n",
       "0    AL         01         001  Autauga County              H1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(amz.head(1))\n",
    "display(moodys.head(1))\n",
    "display(us_county.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "us_county[\"geoid\"]=\"050\"+\"0000\"+\"US\"+us_county[\"state_code\"]+us_county[\"county_code\"]\n",
    "us_county[\"county_state\"]=us_county[\"county\"]+\", \"+us_county[\"state\"]\n",
    "us_county_trimmed = us_county.drop([\"state\",\"state_code\",\"county_code\",\"county\",\"FIPS_class_code\"],axis=1)\n",
    "\n",
    "\n",
    "moodys_2012 = moodys[moodys[\"Years\"]==2012]\n",
    "moodys_2012 = moodys_2012.rename(columns={\"Unnamed: 1\":\"county_state\"})\n",
    "moodys_2012 = moodys_2012.drop([\"Unnamed: 0\"],axis=1)\n",
    "\n",
    "\n",
    "amz[\"county_state\"]=amz.apply(axis=1,func=lambda row:str(row[\"County\"])+\", \" +us_state_abbrev[row[\"State\"]])\n",
    "amz_trimmed = amz[[\"county_state\"]]\n",
    "#t1 = pd.DataFrame(np.ones((amz_trimmed.shape[0],1)),columns=[\"warehouse\"])\n",
    "amz_trimmed=amz_trimmed.assign(warehouse=1)\n",
    "#amz_trimmed[\"warehouse\"]=t1[\"warehouse\"]\n",
    "t1 = pd.merge(how=\"left\",left=moodys_2012,right=amz_trimmed,left_on=\"county_state\",right_on=\"county_state\")\n",
    "\n",
    "\n",
    "t1[\"warehouse\"].fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "t2 = pd.merge(how=\"left\",left =t1,left_on=\"county_state\",right=us_county_trimmed,right_on=\"county_state\")\n",
    "#don't remove dupes add them to a new count column\n",
    "\n",
    "final= t2[t2[\"geoid\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_geo = 'Data\\\\cb_2013_us_county_5m.geojson'\n",
    "\n",
    "\n",
    "m1 = folium.Map(location=[40, -100], zoom_start=4.5)\n",
    "#m.choropleth(geo_data=state_geo, line_color='blue',line_weight=3)\n",
    "m1.choropleth(\n",
    "    geo_data=state_geo,\n",
    "    name='choropleth',\n",
    "    data=final,\n",
    "    columns=['geoid', 'warehouse'],\n",
    "    key_on='feature.properties.AFFGEOID',\n",
    "    fill_color='RdBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Existing Amazon warehouses\"\n",
    ")\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m1)\n",
    "m1.save(\"map1.html\")\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train a logistic regression model and then run it on everything\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "data_1 = final.drop([\"geoid\",\"county_state\",\"State\",\"Code\",\"Include in Amazon Dataset\",\"Years\",\"Current Senior Most Rating*\",\"Tax Backed Rating Description\",\"No. Persons/Household (ACS Data)\"],axis=1)\n",
    "data=data_1.dropna()\n",
    "\n",
    "x=data.ix[:,0:-1]\n",
    "y=data.ix[:,-1]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42)\n",
    "\n",
    "models={}\n",
    "\n",
    "\n",
    "\n",
    "grid_grid={\"logisticregression__solver\":[\"lbfgs\",\"liblinear\",\"newton-cg\"],\"logisticregression__C\":np.logspace(-4,4,10)}\n",
    "\n",
    "\n",
    "#basic logistic regression\n",
    "pipe_1 = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "\n",
    "model_1 = GridSearchCV(pipe_1,grid_grid,cv=3,scoring=\"f1\")\n",
    "model_1.fit(x_train,y_train)\n",
    "models[\"basic_logistic\"]=model_1\n",
    "\n",
    "\n",
    "\n",
    "#Random undersampling\n",
    "#x_train_samp,y_train_samp = RandomUnderSampler(x_train,y_train)\n",
    "x_train_under,y_train_under = RandomUnderSampler(random_state=42).fit_sample(x_train,y_train)\n",
    "pipe_2 = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "model_2 = GridSearchCV(pipe_2,grid_grid,cv=5,scoring=\"f1\")\n",
    "model_2.fit(x_train_under,y_train_under)\n",
    "models[\"random_undersampled\"]=model_2\n",
    "\n",
    "#Smote \n",
    "x_train_smote,y_train_smote = SMOTE(random_state=42).fit_sample(x_train,y_train)\n",
    "pipe_3 = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "model_3 = GridSearchCV(pipe_3,grid_grid,cv=5,scoring=\"f1\")\n",
    "model_3.fit(x_train_smote,y_train_smote)\n",
    "models[\"SMOTE\"]=model_3\n",
    "\n",
    "\n",
    "#Random oversampling\n",
    "x_train_over,y_train_over = RandomOverSampler(random_state=42).fit_sample(x_train,y_train)\n",
    "pipe_4 = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "model_4 = GridSearchCV(pipe_4,grid_grid,cv=5,scoring=\"f1\")\n",
    "model_4.fit(x_train_over,y_train_over)\n",
    "models[\"random_oversampled\"]=model_4\n",
    "\n",
    "\n",
    "\n",
    "#TODO: mutual information\n",
    "\n",
    "\n",
    "junk =[]\n",
    "for k,v in models.items():\n",
    "    stuff =[]\n",
    "    stuff.append(k)\n",
    "    m = models[k]\n",
    "    y_pred = m.predict(x_test)\n",
    "    stuff.append(m.score(x_test,y_test))\n",
    "    stuff.append(recall_score(y_test,y_pred))\n",
    "    stuff.append(precision_score(y_test,y_pred))\n",
    "    junk.append(stuff)\n",
    "m_frame = pd.DataFrame(junk,columns=[\"model\", \"F1_score\",\"recall\",\"precision\"])\n",
    "display(m_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=model_1\n",
    "\n",
    "#plot tp fp fn\n",
    "probabilities = model.predict_proba(x)[:,1]\n",
    "predicted = model.predict(x)\n",
    "data_plus_proba = final.copy()\n",
    "\n",
    "#drop the same rows we dropped from the \"data\" frame\n",
    "data_plus_proba=data_plus_proba.dropna(how=\"all\",subset=data.columns[:-1])\n",
    "\n",
    "data_plus_proba[\"proba\"]=probabilities\n",
    "data_plus_proba[\"predicted\"]=predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_color_function(feature):\n",
    "    \"\"\"map to green if prediction and warehouse are both 1, map to blue \n",
    "    if warehouse but not predicted, map to red if predicted but no warehouse\"\"\"\n",
    "    geoid = feature[\"properties\"][\"AFFGEOID\"]\n",
    "    #there are counties with bounding information we don't have in our dataset\n",
    "    #make them black\n",
    "    raw_row = data_plus_proba[data_plus_proba[\"geoid\"]==geoid]\n",
    "    if raw_row.shape[0]==0:\n",
    "        return \"#000000\"\n",
    "    row = raw_row.iloc[0]\n",
    "    if row[\"warehouse\"]==1 and row[\"predicted\"]==1:\n",
    "        return \"#006600\"\n",
    "    elif row[\"warehouse\"]==1 and row[\"predicted\"]==0:\n",
    "        return \"#000099\"\n",
    "    elif row[\"warehouse\"]==0 and row[\"predicted\"]==1:\n",
    "        return \"#CC0000\"\n",
    "    else:\n",
    "        return \"#FFFFFF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicted results\n",
    "m2 = folium.Map(location=[40, -100], zoom_start=4.5)\n",
    "\n",
    "g1 = folium.features.GeoJson(state_geo,\n",
    "        style_function=lambda feature: {\n",
    "        'fillColor': my_color_function(feature),\n",
    "        'color': 'black',\n",
    "        \"weight\":1,\n",
    "        \"opacity\":.2\n",
    "    })\n",
    "\n",
    "g1.add_to(m2)\n",
    "m2.save(\"map2.html\")\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#probabilities\n",
    "m3 = folium.Map(location=[40, -100], zoom_start=4.5)\n",
    "m3.choropleth(\n",
    "    geo_data=state_geo,\n",
    "    name='choropleth',\n",
    "    data=data_plus_proba,\n",
    "    columns=['geoid', 'proba'],\n",
    "    key_on='feature.properties.AFFGEOID',\n",
    "    fill_color='RdBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Probability of receving amazon warehouse\"\n",
    ")\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m3)\n",
    "m3.save(\"map3.html\")\n",
    "m3\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
